{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('pytorch-env': conda)",
   "display_name": "Python 3.7.6 64-bit ('pytorch-env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "83947e5433b6b9bf40b43e0d8ef9ba0b5948270c99e754a591b62bae71cbdc02"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Reddit_Scraper.RedditScraper import redditscraper\n",
    "from LDA.LDA_Infer import lda_infer\n",
    "import numpy as np\n",
    "import pickle\n",
    "from GUI import gui_interface\n",
    "\n",
    "# gui = gui_interface()\n",
    "\n",
    "# RS = gui.scraper\n",
    "# LDA = lda_infer('LDA\\\\models\\\\hash_vect.pk', 'LDA\\\\models\\\\lda_model_8.pk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "# from pushshift_py import PushshiftAPI\n",
    "from psaw import PushshiftAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = api.search_comments(limit=100)\n",
    "results = list(gen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "uter\n1st round possibly overall\nI was excited early for the game but its not the end of the world. Its obvious they've faced issues which happens.. I haven't watched any of the gameplay previews or anything either though, I'm just going to play it on release without some huge hype and see if its fun rather than counting the hours until release.\nWuhan virus is still out there. just in case anyone forgot.\nBeing a member of the [coolest gang on the internet](http://images2.wikia.nocookie.net/__cb20110705191044/cartoons/images/6/61/Cartoon_All-Stars_to_the_Rescue.png).\nDownload Windows via bootcamp.\n\nProblem solved\nI don’t think they should sell that other shower screen holder. I got the brass one and my puck was getting destroyed because the holes are smaller than on the stock one. I’d get a new stock one. \n\nThe channeling is because your puck prep isn’t on point yet. WDT and a flat tamp will fix that but it might just take a little practice if this is your first time with espresso.\n**Spoiler Warning:** All officially-released show and book content allowed, including trailers and pre-released chapters. No leaked information or paparazzi photos of the set. For more info please check the [spoiler guide](/r/gameofthrones/w/spoiler_guide).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/gameofthrones) if you have any questions or concerns.*\n*muffled screams for help*\nI know. But it's very doubtful that the adjustments suddenly enable everyone to clear the remaining 48 stages in chapter 38.\nSo 38 is still light years away from maxed out players. And that's why I find it very funny. It wasn't criticized.\n"
     ]
    }
   ],
   "source": [
    "for r in results[:10]: print(r.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credentials.txt', 'r') as CF:\n",
    "    CF_Data = CF.read()\n",
    "\n",
    "credentials = {}\n",
    "\n",
    "for Line in CF_Data.splitlines():\n",
    "    if not Line.strip():\n",
    "        continue\n",
    "\n",
    "    Key, Value = Line.split('=')\n",
    "\n",
    "    credentials[Key.strip()] = Value.strip()\n",
    "\n",
    "# Getting a Reddit instance\n",
    "Reddit = praw.Reddit(client_id=credentials['PERSONAL_USE_SCRIPT_14_CHARS'],\n",
    "                        client_secret=credentials['SECRET_KEY_27_CHARS'],\n",
    "                        user_agent=credentials['YOUR_APP_NAME'], \n",
    "                        username=credentials['YOUR_REDDIT_USER_NAME'], \n",
    "                        password=credentials['YOUR_REDDIT_LOGIN_PASSWORD'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI(Reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = api.search_comments(limit=100)\n",
    "results = list(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Yup, G-canon was \"George Canon\", T-canon was for TV shows, C-canon was basically everything else, S-canon was older stuff that didn't quite fit, and then a few levels of non-canon and Infinities.\n\nTFU was canon, just on a lower tier than the films and TV.\n> But if she walks down the street she’s going to get catcalled the same way she would get inundated w messages on an app?\n\nNo she won't. Maybe here and there, but not by literally every guy.\ni think this is one of the worst greatest post i've seen on this subreddit\nJust like that\nWe used to play on the ice clampers.  Would see how far from shore we could make it.\nConfused? You said his post wasn't worth the time and then spent the time to make a post about it....irony. Seems you're confused by a lot.\nI use Party Toughness (extra defense) and Stealth Attack (less agro generation).  Party Toughness is probably more widely useful.\nHonestly? I'd love it if police used other methods to deescalate and disarm a person before killing them. Are there really no other ways that multiple police officers can apprehend someone who has a knife?? I cannot believe this. Please tell me that's not the case.\nHi `Trump_Wears_Diapers`. Thank you for participating in /r/Politics. However, your submission has been removed for the following reason:\n\n* Already Submitted: This article has been submitted to /r/politics within the last three days:\n\nhttps://redd.it/jjkpnt\n\nI'm a bot and sometimes I make mistakes. If you have any questions about this removal, please feel free to [message the moderators.](https://www.reddit.com/message/compose?to=/r/politics&subject=Question regarding the removal of this submission by /u/Trump_Wears_Diapers&message=I have a question regarding the removal of this [submission.](https://www.reddit.com/r/politics/comments/jjnzq7/all_of_the_trumpworld_figures_whove_been_arrested/\\))\n[removed]\n"
     ]
    }
   ],
   "source": [
    "for r in results[:10]: print(r.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "start_epoch=int(dt.datetime(2017, 1, 1).timestamp())\n",
    "\n",
    "\n",
    "c = list(api.search_comments(after='7d',\n",
    "                             subreddit='politics',\n",
    "                             filter=['created_utc','body'],\n",
    "                             sort_type='created_utc',\n",
    "                             sort='asc',\n",
    "                             limit=6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pushshift_data2(topic, limit, after, sort, score='created_utc'):\n",
    "    if isinstance(after, int): \n",
    "        after=int(dt.datetime(after, 1, 1).timestamp())\n",
    "    return list(api.search_comments(after=after,\n",
    "                            subreddit=topic,\n",
    "                            filter=['created_utc','body'],\n",
    "                            sort_type=score,\n",
    "                            sort=sort,\n",
    "                            limit=limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = get_pushshift_data2(after='7d',\n",
    "                            subreddit='politics',\n",
    "                            filter=['created_utc','body'],\n",
    "                            sort_type='created_utc',\n",
    "                            sort='asc',\n",
    "                            limit=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = {\"created\": [], \n",
    "                \"body\":[]}\n",
    "\n",
    "for submission in c:\n",
    "    topics_dict[\"created\"].append(submission.created)\n",
    "    topics_dict[\"body\"].append(submission.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "topics_data = pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "len(topics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "len(topics_data[topics_data['body']=='[removed]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ]
}